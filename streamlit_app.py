import os
import tempfile
import streamlit as st

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain_community.utilities import SerpAPIWrapper
from langchain.agents import Tool, create_tool_calling_agent, AgentExecutor
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_community.chat_message_histories import ChatMessageHistory


# .env íŒŒì¼ ë¡œë“œ
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


# âœ… SerpAPI ê²€ìƒ‰ íˆ´ ì •ì˜ (ì œëª© + ë§í¬ + ì¶œì²˜ + ìŠ¤ë‹ˆí«)
def search_web():
    search = SerpAPIWrapper()

    def run_with_source(query: str) -> str:
        results = search.results(query)
        organic = results.get("organic_results", [])
        formatted = []
        for r in organic[:5]:
            title = r.get("title")
            link = r.get("link")
            source = r.get("source")
            snippet = r.get("snippet", "")
            if link:
                formatted.append(f"- {title} ({source})\n  {snippet}")
            else:
                formatted.append(f"- {title} (ì¶œì²˜: {source})\n  {snippet}")
        return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    return Tool(
        name="web_search",
        func=run_with_source,
        description=(
            "ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë° ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
            "ê²°ê³¼ëŠ” ì œëª©+ì¶œì²˜+ë§í¬+ê°„ë‹¨ìš”ì•½(snippet) í˜•íƒœë¡œ ë°˜í™˜ë©ë‹ˆë‹¤."
        ),
    )


# âœ… PDF ì—…ë¡œë“œ â†’ ë²¡í„°DB â†’ ê²€ìƒ‰ íˆ´ ìƒì„± (+ë©”íƒ€ë°ì´í„° ë³´ê°•: file_name, page)
def load_pdf_files(uploaded_files):
    all_documents = []

    # ì›ë³¸ íŒŒì¼ëª… ë³´ì¡´ì„ ìœ„í•´ ë©”íƒ€ë°ì´í„° ì‚½ì…
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        for d in documents:
            d.metadata["file_name"] = uploaded_file.name  # ì›ë³¸ ì—…ë¡œë“œ íŒŒì¼ëª…
            # PyPDFLoaderëŠ” ë³´í†µ 'page' ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•¨ (0-based). ì—†ìœ¼ë©´ None.

        all_documents.extend(documents)

    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(all_documents)

    # íŒŒì¼ë³„ ê·¸ë£¹í•‘ (ìš”ì•½ì— ì‚¬ìš©)
    grouped_by_file = {}
    for d in split_docs:
        fname = d.metadata.get("file_name", "unknown.pdf")
        grouped_by_file.setdefault(fname, []).append(d)

    # ë²¡í„°DB ìƒì„±
    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever(search_kwargs={"k": 5})

    # âœ… ì»¤ìŠ¤í…€ PDF ê²€ìƒ‰ íˆ´: ìŠ¤ë‹ˆí« + (íŒŒì¼ëª…, í˜ì´ì§€) í•¨ê»˜ ë°˜í™˜
    def run_pdf_search(query: str) -> str:
        docs = retriever.get_relevant_documents(query)
        if not docs:
            return "PDFì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        lines = []
        for i, d in enumerate(docs[:5]):
            file_name = d.metadata.get("file_name") or os.path.basename(d.metadata.get("source", ""))
            page_meta = d.metadata.get("page")
            # PyPDFLoaderëŠ” 0-based í˜ì´ì§€. ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ +1
            page_disp = page_meta + 1 if isinstance(page_meta, int) else page_meta
            snippet = d.page_content.strip().replace("\n", " ")
            lines.append(
                f"{i+1}. {snippet}\n   (ì¶œì²˜: {file_name}, p.{page_disp})"
            )
        return "\n".join(lines)

    retriever_tool = Tool(
        name="pdf_search",
        func=run_pdf_search,
        description=(
            "ì—…ë¡œë“œëœ PDF ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
            "ë°˜í™˜ í˜•ì‹ì€ ìŠ¤ë‹ˆí«ê³¼ í•¨ê»˜ (ì¶œì²˜: íŒŒì¼ëª…, p.í˜ì´ì§€) ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
        ),
    )

    return retriever_tool, grouped_by_file


# âœ… Agent ëŒ€í™” ì‹¤í–‰
def chat_with_agent(user_input, agent_executor):
    result = agent_executor({"input": user_input})
    return result["output"]


# âœ… ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]


# âœ… ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
def print_messages():
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])


# âœ… PDF ìš”ì•½ ìƒì„±
def summarize_pdf_grouped(grouped_docs: dict, llm: ChatOpenAI, max_chunks_per_file: int = 8) -> dict:
    """
    grouped_docs: { file_name: [Document, ...] }
    """
    summaries = {}
    for file_name, docs in grouped_docs.items():
        # ê³¼ë„í•œ í† í° ë°©ì§€ë¥¼ ìœ„í•´ ì•ë¶€ë¶„ ì¼ë¶€ë§Œ ì‚¬ìš©
        take = min(len(docs), max_chunks_per_file)
        contents = "\n\n".join(d.page_content for d in docs[:take])

        prompt = (
            "ë‹¤ìŒì€ ì—…ë¡œë“œëœ PDFì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê³  ëª…ë£Œí•˜ê²Œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
            "- 5~8ì¤„ ì´ë‚´ ìš”ì•½\n"
            "- ì¤‘ìš”í•œ ìˆ˜ì¹˜/í‚¤ì›Œë“œ/ì •ì˜ëŠ” **êµµê²Œ** í‘œì‹œ\n"
            "- ë¬¸ì„œì˜ ì „ë°˜ì  ëª©ì ê³¼ ì£¼ìš” ê²°ë¡ ì„ í¬í•¨\n"
            "- ê°€ëŠ¥í•˜ë©´ (ì¶”ì •) ê·¼ê±°ê°€ ë³´ì´ëŠ” ë¬¸ì¥ë„ í•œ ì¤„ í¬í•¨\n\n"
            f"[ë¬¸ì„œ: {file_name}] ë‚´ìš©:\n{contents}\n\n"
            "ì´ì œ [ìš”ì•½]ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
        )

        # ChatOpenAI.invokeëŠ” ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ë„ í—ˆìš© (AIMessage ë°˜í™˜)
        ai_msg = llm.invoke(prompt)
        summaries[file_name] = ai_msg.content
    return summaries


# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    st.set_page_config(page_title="AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´ (RAG)", layout="wide", page_icon="ğŸ¤–")

    with st.container():
        st.image('./chatbot_logo.png', use_container_width=True)
        st.markdown('---')
        st.title("ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´' ì…ë‹ˆë‹¤")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}
    if "pdf_grouped" not in st.session_state:
        st.session_state["pdf_grouped"] = {}
    if "pdf_summaries" not in st.session_state:
        st.session_state["pdf_summaries"] = {}

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input("OPENAI API í‚¤", placeholder="Enter Your API Key", type="password")
        st.session_state["SERPAPI_API"] = st.text_input("SERPAPI_API í‚¤", placeholder="Enter Your API Key", type="password")
        st.markdown('---')
        pdf_docs = st.file_uploader("Upload your PDF Files", accept_multiple_files=True, key="pdf_uploader")

        # âœ… PDF ìš”ì•½ ìƒì„± ë²„íŠ¼
        if pdf_docs and st.session_state.get("pdf_grouped"):
            if st.button("ğŸ“Œ PDF ìš”ì•½ ìƒì„±"):
                # LLM ì¸ìŠ¤í„´ìŠ¤ê°€ í•„ìš”í•˜ë¯€ë¡œ ì•„ë˜ì—ì„œ ìƒì„±ëœ llmì„ ë‹¤ì‹œ ìƒì„±
                llm_for_summary = ChatOpenAI(model="gpt-4o-mini", temperature=0)
                with st.spinner("PDF ìš”ì•½ ìƒì„± ì¤‘..."):
                    st.session_state["pdf_summaries"] = summarize_pdf_grouped(
                        st.session_state["pdf_grouped"], llm_for_summary, max_chunks_per_file=8
                    )
                st.success("PDF ìš”ì•½ ìƒì„± ì™„ë£Œ!")

    # âœ… í‚¤ ì…ë ¥ í™•ì¸
    if st.session_state["OPENAI_API"] and st.session_state["SERPAPI_API"]:
        os.environ["OPENAI_API_KEY"] = st.session_state["OPENAI_API"]
        os.environ["SERPAPI_API_KEY"] = st.session_state["SERPAPI_API"]

        # ë„êµ¬ ì •ì˜
        tools = []
        if pdf_docs:
            pdf_search_tool, grouped_by_file = load_pdf_files(pdf_docs)
            tools.append(pdf_search_tool)
            st.session_state["pdf_grouped"] = grouped_by_file  # ìš”ì•½ì— í™œìš©
        tools.append(search_web())

        # âœ… LLM ì„¤ì • (í˜¸í™˜ë˜ëŠ” íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # âœ… ì‘ë‹µ í˜•ì‹ ê°•í™” (ìš”ì•½ í‘œ + ì¶œì²˜ í‘œ)
        prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì—…ë¬´ìš© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                    "ë‹¹ì‹ ì˜ ì´ë¦„ì€ `AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´`ì…ë‹ˆë‹¤. ëŒ€í™” ì‹œì‘ ì‹œ ì§§ê²Œ ìê¸°ì†Œê°œí•˜ì„¸ìš”. "
                    "ì‚¬ìš©ìì˜ ìš”ì²­ì´ PDF ê¸°ë°˜ì´ë©´ **ë°˜ë“œì‹œ** `pdf_search` íˆ´ì„ ë¨¼ì € í˜¸ì¶œí•´ ê´€ë ¨ ìŠ¤ë‹ˆí«ê³¼ (íŒŒì¼ëª…, í˜ì´ì§€)ë¥¼ í™•ë³´í•˜ì„¸ìš”. "
                    "PDFì—ì„œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì§ˆë¬¸ì— 'ìµœì‹ ', 'í˜„ì¬', 'ì˜¤ëŠ˜'ì´ í¬í•¨ë˜ë©´ `web_search` íˆ´ì„ ì‚¬ìš©í•˜ì„¸ìš”. "
                    "ì‘ë‹µì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:\n"
                    "1) í•µì‹¬ ìš”ì•½ì„ **ê°„ë‹¨í•œ í‘œ**ë¡œ ì œì‹œ\n"
                    "2) í•„ìš”í•œ ê²½ìš° ê°„ë‹¨í•œ bullet ì„¤ëª…\n"
                    "3) ë§ˆì§€ë§‰ì— **ì¶œì²˜ í‘œ**ë¥¼ ì œê³µí•©ë‹ˆë‹¤. PDFëŠ” (íŒŒì¼ëª…, í˜ì´ì§€), ì›¹ì€ (ì œëª©/ë„ë©”ì¸, ë§í¬)\n"
                    "ë‹µë³€ì—ëŠ” í•­ìƒ ì´ëª¨ì§€ë¥¼ í¬í•¨í•˜ê³ , ì¹œê·¼í•˜ê³  ê°„ê²°í•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”."
                ),
                ("placeholder", "{chat_history}"),
                ("human", "{input}\n\n Be sure to include emoji in your responses."),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

        # ì…ë ¥ì°½
        user_input = st.chat_input("ì–´ì„œì˜¤ì„¸ìš”. ì˜¤ëŠ˜ì€ ì–´ë–¤ ë„ì›€ì„ ë“œë¦´ê¹Œìš”?")
        if user_input:
            session_id = "default_session"
            session_history = get_session_history(session_id)

            if session_history.messages:
                prev_msgs = [{"role": msg["role"], "content": msg["content"]} for msg in session_history.messages]
                response = chat_with_agent(user_input + "\n\nPrevious Messages: " + str(prev_msgs), agent_executor)
            else:
                response = chat_with_agent(user_input, agent_executor)

            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

            session_history.add_message({"role": "user", "content": user_input})
            session_history.add_message({"role": "assistant", "content": response})

        print_messages()

        # âœ… ìƒì„±ëœ PDF ìš”ì•½ ì„¹ì…˜ (ìˆì„ ë•Œë§Œ í‘œì‹œ)
        if st.session_state["pdf_summaries"]:
            st.markdown("---")
            st.subheader("ğŸ“š ì—…ë¡œë“œëœ PDF ìš”ì•½")
            for fname, summ in st.session_state["pdf_summaries"].items():
                with st.expander(f"ğŸ“ {fname} ìš”ì•½ ë³´ê¸°"):
                    st.write(summ)

    else:
        st.warning("OpenAI API í‚¤ì™€ SerpAPI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")



