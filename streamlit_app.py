import os
import tempfile
import streamlit as st

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader

from langchain_community.utilities import SerpAPIWrapper
from langchain.agents import Tool, create_tool_calling_agent, AgentExecutor

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain.schema import HumanMessage, AIMessage


# --------- ì „ì—­ ì„¤ì • ----------
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"


# âœ… SerpAPI ê²€ìƒ‰ íˆ´
def search_web():
    search = SerpAPIWrapper()

    def run_with_source(query: str) -> str:
        results = search.results(query)
        organic = results.get("organic_results", [])
        formatted = []
        for r in organic[:5]:
            title = r.get("title")
            link = r.get("link")
            source = r.get("source")
            snippet = r.get("snippet", "")
            if link:
                formatted.append(f"- {title} ({source})\n  {snippet}")
            else:
                formatted.append(f"- {title} (ì¶œì²˜: {source})\n  {snippet}")
        return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    return Tool(
        name="web_search",
        func=run_with_source,
        description="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë° ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì œëª©/ì¶œì²˜/ë§í¬/ìŠ¤ë‹ˆí« ë°˜í™˜)"
    )


# âœ… PDF ì—…ë¡œë“œ â†’ ë²¡í„°DB â†’ ê²€ìƒ‰ íˆ´ ìƒì„± (+ ë©”íƒ€ë°ì´í„° ë³´ê°•)
def load_pdf_files(uploaded_files):
    all_documents = []

    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        for d in documents:
            d.metadata["file_name"] = uploaded_file.name  # ì›ë³¸ ì—…ë¡œë“œ íŒŒì¼ëª…

        all_documents.extend(documents)

    # ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(all_documents)

    # íŒŒì¼ë³„ ê·¸ë£¹í•‘ (ìš”ì•½ìš©)
    grouped_by_file = {}
    for d in split_docs:
        fname = d.metadata.get("file_name", "unknown.pdf")
        grouped_by_file.setdefault(fname, []).append(d)

    # ë²¡í„°DB ìƒì„±
    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever(search_kwargs={"k": 5})

    # PDF ê²€ìƒ‰ íˆ´: ìŠ¤ë‹ˆí« + (íŒŒì¼ëª…, í˜ì´ì§€)
    def run_pdf_search(query: str) -> str:
        docs = retriever.get_relevant_documents(query)
        if not docs:
            return "PDFì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        lines = []
        for i, d in enumerate(docs[:5]):
            file_name = d.metadata.get("file_name") or os.path.basename(d.metadata.get("source", ""))
            page_meta = d.metadata.get("page")
            page_disp = page_meta + 1 if isinstance(page_meta, int) else page_meta
            snippet = d.page_content.strip().replace("\n", " ")
            lines.append(f"{i+1}. {snippet}\n   (ì¶œì²˜: {file_name}, p.{page_disp})")
        return "\n".join(lines)

    retriever_tool = Tool(
        name="pdf_search",
        func=run_pdf_search,
        description="ì—…ë¡œë“œëœ PDFì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ìŠ¤ë‹ˆí« + ì¶œì²˜: íŒŒì¼ëª…, í˜ì´ì§€)"
    )

    return retriever_tool, grouped_by_file


# âœ… PDF ìš”ì•½
def summarize_pdf_grouped(grouped_docs: dict, llm: ChatOpenAI, max_chunks_per_file: int = 8) -> dict:
    summaries = {}
    for file_name, docs in grouped_docs.items():
        take = min(len(docs), max_chunks_per_file)
        contents = "\n\n".join(d.page_content for d in docs[:take])

        prompt = (
            "ë‹¤ìŒì€ ì—…ë¡œë“œëœ PDFì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ê°„ë‹¨í•˜ê²Œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
            "- 5~8ì¤„ ìš”ì•½\n- ì¤‘ìš”í•œ ìˆ˜ì¹˜/í‚¤ì›Œë“œ/ì •ì˜ëŠ” **êµµê²Œ**\n- ë¬¸ì„œ ëª©ì ê³¼ ì£¼ìš” ê²°ë¡  í¬í•¨\n"
            f"[ë¬¸ì„œ: {file_name}] ë‚´ìš©:\n{contents}\n\n"
            "ì´ì œ [ìš”ì•½]ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
        )
        ai_msg = llm.invoke(prompt)
        summaries[file_name] = ai_msg.content
    return summaries


# âœ… ì„¸ì…˜ íˆìŠ¤í† ë¦¬
def get_session_history(session_id: str) -> ChatMessageHistory:
    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}
    if session_id not in st.session_state["session_history"]:
        st.session_state["session_history"][session_id] = ChatMessageHistory()
    return st.session_state["session_history"][session_id]


# âœ… ì´ì „ ë©”ì‹œì§€ ì¶œë ¥ (UI)
def print_messages():
    if "messages" not in st.session_state:
        return
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])


# âœ… ë©”ì¸
def main():
    # ë°˜ë“œì‹œ ì²« Streamlit í˜¸ì¶œ
    st.set_page_config(page_title="AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´ (RAG)", layout="wide", page_icon="ğŸ¤–")

    # ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.setdefault("messages", [])
    st.session_state.setdefault("pdf_grouped", {})
    st.session_state.setdefault("pdf_summaries", {})

    # í—¤ë”
    with st.container():
        try:
            st.image("./chatbot_logo.png", width="stretch", use_container_width=True,use_column_width="always")
        except Exception:
            st.info("ë¡œê³  ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (chatbot_logo.png)")
        st.markdown('---')
        st.title("ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´' ì…ë‹ˆë‹¤ ğŸ‘‹")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input("OPENAI API í‚¤", placeholder="Enter Your API Key", type="password")
        st.session_state["SERPAPI_API"] = st.text_input("SERPAPI_API í‚¤", placeholder="Enter Your API Key", type="password")
        st.markdown('---')
        pdf_docs = st.file_uploader("Upload your PDF Files", accept_multiple_files=True, key="pdf_uploader")

        # ìš”ì•½ ë²„íŠ¼ì€ íŒŒì¼ ì—…ë¡œë“œ ì´í›„ ë…¸ì¶œ
        if pdf_docs:
            if st.button("ğŸ“Œ PDF ìš”ì•½ ìƒì„±"):
                if not st.session_state.get("pdf_grouped"):
                    st.warning("ë¨¼ì € í‚¤ ì…ë ¥ í›„ PDFë¥¼ ë¡œë”©í•˜ì„¸ìš”.")
                else:
                    llm_for_summary = ChatOpenAI(model="gpt-4o-mini", temperature=0)
                    with st.spinner("PDF ìš”ì•½ ìƒì„± ì¤‘..."):
                        st.session_state["pdf_summaries"] = summarize_pdf_grouped(
                            st.session_state["pdf_grouped"], llm_for_summary, max_chunks_per_file=8
                        )
                    st.success("PDF ìš”ì•½ ìƒì„± ì™„ë£Œ!")

    # ë³¸ë¬¸ â€” í‚¤ ë¯¸ì…ë ¥ ì‹œì—ë„ ê¸°ë³¸ UI ë³´ì´ë„ë¡ ë¨¼ì € ë Œë”
    st.markdown("### ëŒ€í™”")
    user_input = st.chat_input("ì–´ì„œì˜¤ì„¸ìš”. ì˜¤ëŠ˜ì€ ì–´ë–¤ ë„ì›€ì„ ë“œë¦´ê¹Œìš”?")

    # í‚¤ í™•ì¸ í›„ ì—ì´ì „íŠ¸/íˆ´ ì¤€ë¹„
    agent_executor = None
    if st.session_state["OPENAI_API"] and st.session_state["SERPAPI_API"]:
        os.environ["OPENAI_API_KEY"] = st.session_state["OPENAI_API"]
        os.environ["SERPAPI_API_KEY"] = st.session_state["SERPAPI_API"]

        tools = []
        if pdf_docs:
            pdf_search_tool, grouped_by_file = load_pdf_files(pdf_docs)
            tools.append(pdf_search_tool)
            st.session_state["pdf_grouped"] = grouped_by_file
        tools.append(search_web())

        # LLM
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        # Prompt
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system",
                 "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì—…ë¬´ìš© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                 "ë‹¹ì‹ ì˜ ì´ë¦„ì€ `AI ë¹„ì„œ ë°±ìˆ˜ì„-ì—”ì§€ë‹ˆì–´`ì…ë‹ˆë‹¤. ëŒ€í™” ì‹œì‘ ì‹œ ì§§ê²Œ ìê¸°ì†Œê°œí•˜ì„¸ìš”. "
                 "PDF ê¸°ë°˜ì´ë©´ `pdf_search`ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , 'ìµœì‹ /í˜„ì¬/ì˜¤ëŠ˜' ì§ˆë¬¸ì´ë©´ `web_search`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
                 "ì‘ë‹µ í˜•ì‹: 1) í•µì‹¬ ìš”ì•½ í‘œ 2) í•„ìš” ì‹œ ì§§ì€ bullet 3) ë§ˆì§€ë§‰ì— ì¶œì²˜ í‘œ. "
                 "í•­ìƒ ì´ëª¨ì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”."),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}\n\nBe sure to include emoji in your responses."),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ]
        )

        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            handle_parsing_errors=True
        )

    # ëŒ€í™” ì²˜ë¦¬
    session_id = "default_session"
    session_history = get_session_history(session_id)

    if user_input:
        if agent_executor:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                result = agent_executor.invoke({
                    "input": user_input,
                    "chat_history": session_history.messages  # <-- í•µì‹¬ ìˆ˜ì •
                })
                response = result["output"]
        else:
            response = "âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì— OpenAI/SerpAPI í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

        # UI ê¸°ë¡
        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.session_state["messages"].append({"role": "assistant", "content": response})

        # LangChain íˆìŠ¤í† ë¦¬ ê¸°ë¡ (BaseMessage)
        session_history.add_user_message(user_input)
        session_history.add_ai_message(response)

    # ë©”ì‹œì§€ ì¶œë ¥
    print_messages()

    # PDF ìš”ì•½ ì¶œë ¥
    if st.session_state["pdf_summaries"]:
        st.markdown("---")
        st.subheader("ğŸ“š ì—…ë¡œë“œëœ PDF ìš”ì•½")
        for fname, summ in st.session_state["pdf_summaries"].items():
            with st.expander(f"ğŸ“ {fname} ìš”ì•½ ë³´ê¸°"):
                st.write(summ)


if __name__ == "__main__":
    main()
